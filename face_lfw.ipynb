{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfwk8NjFAegR",
        "outputId": "5bc4975a-287a-4f4d-86ea-fa8ff158b160"
      },
      "outputs": [],
      "source": [
        "!pip install keras==3.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAOGuBsp4ITY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import ops\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2H2GnXtxfFJ5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import base64\n",
        "import imageio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2t7N12df5qW",
        "outputId": "2b3e66ab-acc1-47ac-dc55-c5187f0b747f"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "nFtX1Kjvh7nH",
        "outputId": "c85ac79a-c010-4476-8d24-8236fde143c1"
      },
      "outputs": [],
      "source": [
        "# Step 2: Upload Kaggle API Key\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik6-RvWviDua"
      },
      "outputs": [],
      "source": [
        "# Move the uploaded kaggle.json to ~/.kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t6X2HdciJfJ",
        "outputId": "5751b80b-dee9-47f9-8367-09d6fb7bca97"
      },
      "outputs": [],
      "source": [
        "# Step 3: Download and Unzip the Dataset\n",
        "!kaggle datasets download -d jessicali9530/lfw-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mXdbiZ9l0EO",
        "outputId": "10608a59-ce10-4d70-c810-76ad8cd99711"
      },
      "outputs": [],
      "source": [
        "!unzip lfw-dataset.zip -d lfw-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69yeO4pMmQhb"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_0MM8zLmSmS"
      },
      "outputs": [],
      "source": [
        "# Paths to the downloaded dataset and attributes\n",
        "DATASET_PATH = \"/content/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled\"\n",
        "#ATTRIBUTES_PATH = \"lfw_attributes.txt\"\n",
        "\n",
        "# Load the dataset\n",
        "dataset = []\n",
        "for path in glob.iglob(os.path.join(DATASET_PATH, \"**\", \"*.jpg\")):\n",
        "    person = path.split(\"/\")[-2]\n",
        "    dataset.append({\"person\": person, \"path\": path})\n",
        "\n",
        "dataset = pd.DataFrame(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkHMOWBkmoQi"
      },
      "outputs": [],
      "source": [
        "# Filter the dataset (too much Bush)\n",
        "dataset = dataset.groupby(\"person\").filter(lambda x: len(x) < 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8cjcghXnMQj",
        "outputId": "4645c7f4-ce34-4afd-d580-cd22e919a916"
      },
      "outputs": [],
      "source": [
        "# Display the first 10 entries\n",
        "print(dataset.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "t1Lw8wZincdc",
        "outputId": "b26030ec-d143-4095-99d4-112c3779176f"
      },
      "outputs": [],
      "source": [
        "# Plot the first 200 persons' counts\n",
        "dataset.groupby(\"person\").count()[:200].plot(kind='bar', figsize=(20, 5))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "tsYaTynanmVk",
        "outputId": "87566624-ba9a-444b-972d-dce1ad9231bc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "for i in range(20):\n",
        "    idx = random.randint(0, len(dataset))\n",
        "    img = plt.imread(dataset.path.iloc[idx])\n",
        "    plt.subplot(4, 5, i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(dataset.person.iloc[idx])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqjJrRrioJNk",
        "outputId": "3d426110-c853-4478-914e-a77c7c8d3118"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d averkij/lfw-attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rauviN5nooG1",
        "outputId": "17d77362-93d2-4248-d4cd-7f633ce173c2"
      },
      "outputs": [],
      "source": [
        "!unzip lfw-attributes.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHBsMcSGpUvf"
      },
      "outputs": [],
      "source": [
        "ATTRIBUTES_PATH = \"/content/lfw_attributes.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5v375nUqHpo"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import imageio\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Define the function to fetch and preprocess the dataset\n",
        "def fetch_dataset(dx=80, dy=80, dimx=64, dimy=64):\n",
        "    # Read the attributes file\n",
        "    df_attrs = pd.read_csv(ATTRIBUTES_PATH, sep='\\t', skiprows=1)\n",
        "    df_attrs = pd.DataFrame(df_attrs.iloc[:, :-1].values, columns=df_attrs.columns[1:])\n",
        "\n",
        "    # List to hold photo details\n",
        "    photo_ids = []\n",
        "    for dirpath, dirnames, filenames in os.walk(DATASET_PATH):\n",
        "        for fname in filenames:\n",
        "            if fname.endswith(\".jpg\"):\n",
        "                fpath = os.path.join(dirpath, fname)\n",
        "                photo_id = fname[:-4].replace('_', ' ').split()\n",
        "                person_id = ' '.join(photo_id[:-1])\n",
        "                photo_number = int(photo_id[-1])\n",
        "                photo_ids.append({'person': person_id, 'imagenum': photo_number, 'photo_path': fpath})\n",
        "\n",
        "    # Create a DataFrame from the photo details\n",
        "    photo_ids = pd.DataFrame(photo_ids)\n",
        "    df = pd.merge(df_attrs, photo_ids, on=('person', 'imagenum'))\n",
        "\n",
        "    # Ensure no data is lost during merge\n",
        "    assert len(df) == len(df_attrs), \"lost some data when merging dataframes\"\n",
        "\n",
        "    # Preprocess images\n",
        "    all_photos = df['photo_path'].apply(imageio.imread)\\\n",
        "                                 .apply(lambda img: img[dy:-dy, dx:-dx])\\\n",
        "                                 .apply(lambda img: np.array(Image.fromarray(img).resize([dimx, dimy])))\n",
        "\n",
        "    # Stack all photos into a numpy array\n",
        "    all_photos = np.stack(all_photos.values).astype('uint8')\n",
        "    # Drop unnecessary columns from attributes\n",
        "    all_attrs = df.drop([\"photo_path\", \"person\", \"imagenum\"], axis=1)\n",
        "\n",
        "    return all_photos, all_attrs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE0El3eYrA5v"
      },
      "outputs": [],
      "source": [
        "data, attrs = fetch_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNCiuw9trcZd",
        "outputId": "603f1904-8634-4f5e-ab88-3c50c5c4705c"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHNdjhpWswrF"
      },
      "outputs": [],
      "source": [
        "#normalization of dataset\n",
        "data = np.array(data / 255, dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNR28ZsxzMay"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fE-5ritFytL",
        "outputId": "e5f7b061-8a7e-44be-8814-07032cb8f747"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check TensorFlow version\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4Fw5MBk0V_L"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-O2EwFuhfa-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Assuming 'images' is your numpy array of shape (500, 64, 64, 3)\n",
        "# Normalize the images to the range [0, 1]\n",
        "#images = images.astype('float32') / 255.\n",
        "\n",
        "# VAE parameters\n",
        "input_shape = (64, 64, 3)\n",
        "latent_dim = 128\n",
        "batch_size = 64\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = keras.Input(shape=input_shape)\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(16 * latent_dim, activation=\"relu\")(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "\n",
        "class Sampling(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "\n",
        "# Decoder\n",
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(16 * 16 * 64, activation=\"relu\")(latent_inputs)\n",
        "x = layers.Reshape((16, 16, 64))(x)\n",
        "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "decoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "\n",
        "# VAE model\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.total_loss_tracker, self.reconstruction_loss_tracker, self.kl_loss_tracker]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n",
        "vae = VAE(encoder, decoder)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnCRSw_vn1Sq"
      },
      "source": [
        "# training and saving the weights after every epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HCoPm_XqiaQt",
        "outputId": "2e6b39cc-0915-41db-f8f6-6f168fef091f"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"training_1/cp.weights.h5\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "# Compile and train\n",
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "vae.fit(data, epochs=100, batch_size=batch_size, callbacks=[cp_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtPAYxTnvKPj"
      },
      "outputs": [],
      "source": [
        "#function for random sampling from normal distribution\n",
        "def generate_faces(num_samples):\n",
        "    z_sample = np.random.normal(size=(num_samples, latent_dim))\n",
        "    return vae.decoder.predict(z_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8xXjcuTuPma"
      },
      "outputs": [],
      "source": [
        "# Function to display generated images\n",
        "def display_generated_images(generated_images, n=10):\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(n):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(generated_images[i])\n",
        "        plt.title(\"Generated\")\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "AHteDwtUua09",
        "outputId": "7aaaa182-eaac-442c-9507-449e0352c18c"
      },
      "outputs": [],
      "source": [
        "# Generate and display new faces\n",
        "new_faces = generate_faces(10)\n",
        "display_generated_images(new_faces)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
